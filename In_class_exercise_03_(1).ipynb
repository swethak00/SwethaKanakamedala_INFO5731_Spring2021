{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03 (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swethak00/SwethaKanakamedala_INFO5731_Spring2021/blob/main/In_class_exercise_03_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqvLnn0AMbvO"
      },
      "source": [
        "## The third In-class-exercise (9/16/2020, 20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1X7j8HuMbvR"
      },
      "source": [
        "The purpose of this exercise is to under users' information needs, then collect the data for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b5h2BZkMbvS"
      },
      "source": [
        "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4lTkuacMbvT"
      },
      "source": [
        "'''\n",
        "As I was searching for restaurants near by I came across a website named 'Yelp' which got me an interest to know the response from the people who ordered or has been to the place. Now I got an oppartunity to analyse anyn data. So, I took this data to analysis in this exercise.\n",
        "\n",
        "Research Question: What would be the restaurant name, url review, name and rating in Yelp?\n",
        "    Yelp is a website and mobile app that connects people with great local businesses. It has over 199 million reviews of businesses worldwide. In simple words it is a local guide for finding the perfect place to eat, shop, explore etc.\n",
        "\n",
        "Data required for this research is to have the name of the viewer, name of the restaurant and it's url and the rating of particular restaurant a person gave. We need about 500 reviews to get the accurate results for this research.\n",
        "\n",
        "Detailed steps for collecting and saving data:\n",
        "1. I have used beautiful soup library to extract the reviews of the restaurant.\n",
        "2. I have extracted reviews using classname from page source and appended to the empty list created in the program.\n",
        "3. To extract 500 reviews where I need to iterate it for 50 times and each page would have the reviews of 10 and generated the url dynamically.\n",
        "4. Then I created a dataframe and converted the dataframe into csv.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTh_EjQzMbvU"
      },
      "source": [
        "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVogVj5iMbvV",
        "outputId": "e89028ba-27ca-4e13-c751-edafe39f0854"
      },
      "source": [
        "%pip install install requests beautifulsoup4 \n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "def scrapData(url):\n",
        "  r  =  requests.get(url, timeout=(3.05, 27))\n",
        "  \n",
        "  if r.status_code > 500:\n",
        "        if \"To discuss automated access to Yelpdata please contact\" in r.text:\n",
        "            print(\"Page %s was blocked by Yelp. Please try using better proxies\\n\"%url)\n",
        "        else:\n",
        "            print(\"Page %s must have been blocked by Yelp as the status code was %d\"%(url,r.status_code))\n",
        "        return None\n",
        "  html_content =  r.text\n",
        "  soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "  list_review_raw = soup.select('[aria-label*=\"Recommended Reviews\"]')[0].findAll('li')\n",
        "  name_raw = soup.findAll(\"h1\")\n",
        "  rest_name = name_raw[0].text\n",
        "  print(name_raw[0].text)\n",
        "  ret = []\n",
        "  for revw_raw in list_review_raw:\n",
        "    r = []\n",
        "    \n",
        "    name_raw = revw_raw.findAll(\"div\", {\"class\": \"user-passport-info\"})\n",
        "    rating_raw = revw_raw.select('[aria-label*=\"star rating\"]')\n",
        "    if len(name_raw) > 0 :\n",
        "      if name_raw[0]  :\n",
        "        r.append(rest_name)\n",
        "        r.append(url)\n",
        "        r.append(name_raw[0].span.text)\n",
        "        #print(name_raw[0].span.text)\n",
        "    if len(rating_raw)>0:\n",
        "      if rating_raw[0]:\n",
        "        r.append(rating_raw[0]['aria-label'])\n",
        "        #print(rating_raw[0]['aria-label'])\n",
        "    ret.append(r)\n",
        "  return ret\n",
        "def main():\n",
        "  fields = ['Name_Restaurant', 'url', 'name_reviwer', 'rating']\n",
        "  with open(\"urls.txt\",'r') as urllist, open(\"output.csv\", 'w', newline='') as csvfile:\n",
        "\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    csvwriter.writerow(fields)\n",
        "    for url in urllist:\n",
        "      rows = scrapData(url)\n",
        "      for row in rows:\n",
        "        if len(row)==4:\n",
        "          csvwriter.writerow(row)\n",
        "\n",
        "\n",
        "  \n",
        "  return\n",
        "main()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: install in /usr/local/lib/python3.6/dist-packages (1.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Banh Mi Station\n",
            "Palmer's Hot Chicken\n",
            "Smokin' Joes\n",
            "The Porch\n",
            "Marugame Udon\n",
            "Ellen's\n",
            "Hudson House\n",
            "Paradiso\n",
            "Ngon Vietnamese Kitchen\n",
            "K Pop Ramen\n",
            "Chelsea Corner\n",
            "Son of a Butcher\n",
            "il Bracco\n",
            "Fachini\n",
            "Lounge 31\n",
            "Royal 38\n",
            "Rodeo Goat\n",
            "Yardbird Southern Table & Bar\n",
            "Red Stix Street Food\n",
            "Eataly-Dallas\n",
            "Hungry Belly\n",
            "Drake's\n",
            "Mike's Chicken\n",
            "XOXO Dining Room\n",
            "La La Land Kind Cafe\n",
            "Meso Maya Comida y Copas\n",
            "Taverna\n",
            "Original ChopShop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}